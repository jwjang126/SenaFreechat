# ğŸ”Š SENA - ë²„íŠ¼ ê¸°ë°˜ ë…¹ìŒ + ëŒ€í™” ë¡œê·¸
# (LEVEL/TOPIC ì„ íƒ + ë¬´ìŒìë™/ê³ ì •ê¸¸ì´ ì„ íƒ + ì „ì²´ ëŒ€í™” ë‹¤ìš´ë¡œë“œ)
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from TTS.api import TTS
import sounddevice as sd
import numpy as np
import tempfile
import soundfile as sf
import time
import json, csv
from io import StringIO

# ===============================
# ê¸°ë³¸ ì„¤ì •
# ===============================
MODEL_NAME = "Qwen/Qwen2.5-3B-Instruct"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
KEEP_LAST_TURNS = 8  # ëª¨ë¸ í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ìµœê·¼ í„´ ìˆ˜(ì „ì²´ ë¡œê·¸ëŠ” ë³„ë„ë¡œ ëª¨ë‘ ë³´ê´€)

# ===============================
# ëª¨ë¸ / TTS ë¡œë“œ
# ===============================
@st.cache_resource(show_spinner=True)
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)
    return tokenizer, model

tokenizer, model = load_model()

@st.cache_resource
def load_tts():
    tts = TTS(
        model_name="tts_models/en/ljspeech/tacotron2-DDC",
        progress_bar=False,
        gpu=torch.cuda.is_available()
    )
    return tts

tts = load_tts()

# ===============================
# ì„¸ì…˜ ìƒíƒœ
# ===============================
if "conversation" not in st.session_state:
    st.session_state.conversation = []  # [{user: "...", ai: "..."}]

# ===============================
# ë…¹ìŒ í•¨ìˆ˜ë“¤
# ===============================
def record_audio_fixed(duration=5, fs=16000):
    """duration ì´ˆ ë™ì•ˆ ë…¹ìŒí•˜ê³  ë°˜í™˜ (ê³ ì • ê¸¸ì´)"""
    st.info(f"ğŸ”´ Listening for {duration} seconds...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
    sd.wait()
    st.success("âœ… Finished!")
    return (audio.flatten().astype(np.float32) / 32768.0), fs

def record_audio_vad(silence_sec=2.0, fs=16000, silence_thresh=0.01, max_total_sec=15):
    """ë¬´ìŒì´ silence_sec ì´ìƒ ì§€ì†ë˜ë©´ ìë™ ì¢…ë£Œ. ì•ˆì „ìƒ max_total_sec ë„˜ì–´ê°€ë©´ ê°•ì œ ì¢…ë£Œ."""
    st.info(f"ğŸ”´ Listeningâ€¦ ë¬´ìŒ {silence_sec}ì´ˆ ì§€ì† ì‹œ ìë™ ì¢…ë£Œ (ìµœëŒ€ {max_total_sec}ì´ˆ)")
    frames = []
    block_dur = 0.05  # 50 ms
    block_size = int(fs * block_dur)
    silent_run = 0.0
    start = time.time()

    with sd.InputStream(samplerate=fs, channels=1, dtype="float32") as stream:
        while True:
            block, _ = stream.read(block_size)
            x = block[:, 0]
            frames.append(x.copy())
            rms = float(np.sqrt(np.mean(x**2) + 1e-12))
            silent_run = (silent_run + block_dur) if rms < silence_thresh else 0.0
            if silent_run >= silence_sec:
                break
            if time.time() - start >= max_total_sec:
                break

    audio = np.concatenate(frames).astype(np.float32) if frames else np.zeros(0, dtype=np.float32)
    st.success("âœ… Finished!")
    return audio, fs

# ===============================
# STT
# ===============================
def run_stt(audio, fs):
    tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
    sf.write(tmp.name, audio, fs)
    import whisper  # openai-whisper (ffmpeg í•„ìš”)
    model_w = whisper.load_model("base", device="cpu")
    result = model_w.transcribe(tmp.name, task="transcribe", language="en", temperature=0)
    return result.get("text", "").strip()

# ===============================
# LLM ì‘ë‹µ ìƒì„±
# ===============================
def build_history_text():
    """ìµœê·¼ KEEP_LAST_TURNSë¥¼ 'Student/Tutor' í¬ë§·ìœ¼ë¡œ ì§ë ¬í™”"""
    lines = []
    for turn in st.session_state.conversation[-KEEP_LAST_TURNS:]:
        user = turn.get("user", "").strip()
        ai   = turn.get("ai", "").strip()
        if user:
            lines.append(f"Student: {user}")
        if ai:
            lines.append(f"Tutor: {ai}")
    return "\n".join(lines)

def generate_ai_response(user_input: str, system_prompt: str):
    conversation_text = build_history_text()
    prompt = f"""
# System
{system_prompt}

# Conversation so far
{conversation_text if conversation_text else "(no previous turns)"}

# Task
Student: "{user_input.strip()}"
Tutor:
""".strip()

    inputs = tokenizer(prompt, return_tensors="pt").to(DEVICE)
    outputs = model.generate(
        **inputs,
        max_new_tokens=120,
        temperature=0.7,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id,
    )
    text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()

    reply = text
    if "Tutor:" in text:
        reply = text.split("Tutor:")[-1].strip()
    if reply.startswith("Student:"):
        reply = reply.split("Student:", 1)[-1].strip()
    return reply

# ===============================
# TTS ì¬ìƒ
# ===============================
def speak(text):
    if not text.strip():
        text = "Hello."
    elif len(text.strip()) < 5:
        text = text.strip() + " okay."

    try:
        wav = tts.tts(text=text)
    except RuntimeError as e:
        st.error(f"TTS ì˜¤ë¥˜ ë°œìƒ: {e}")
        text = "Let me try again."
        wav = tts.tts(text=text)

    sr = tts.synthesizer.output_sample_rate
    sd.play(wav, samplerate=sr)
    sd.wait()
    return wav, sr

# ===============================
# Streamlit UI
# ===============================
st.title("ğŸ”Š SENA - English Tutor")
st.write("ğŸ¤ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”í•˜ì„¸ìš”!")

# --- (1) LEVEL / TOPIC ì„ íƒ â†’ SYSTEM_PROMPT ë°˜ì˜ ---
LEVEL = st.selectbox("í•™ìŠµì ìˆ˜ì¤€", ["beginner", "intermediate", "advanced"], index=0)
TOPIC = st.text_input("ëŒ€í™” ì£¼ì œ", value="ordering food at a restaurant")

RESPONSE_LENGTH_MAP = {
    "beginner": "Answer in 1~2 short and simple sentences.",
    "intermediate": "Answer in 3~4 sentences with some detail.",
    "advanced": "Answer in 5 or more sentences with rich vocabulary and detail."
}
RESPONSE_LENGTH = RESPONSE_LENGTH_MAP[LEVEL]
SUBJECT = (
    "You are a 27-year-old American.\n"
    "Your job is an English speech teacher."
)
SYSTEM_PROMPT = f"""
The user is an English learner at {LEVEL} level.
You are their teacher, and your role is to help them improve fluency, pronunciation, and natural expressions.

Conversation topic: {TOPIC}

Guidelines:
- Always stay in character as {SUBJECT}.
- {RESPONSE_LENGTH}
- Correct the user's mistakes gently and provide the correct way to say it.
- Encourage the user to respond with slightly longer sentences each time.
- Keep your tone friendly, supportive, and engaging.
- Always keep the conversation related to the topic: "{TOPIC}".
- Ask simple follow-up questions appropriate to the user's level and the topic.
""".strip()

st.divider()

# --- (3) ë…¹ìŒ ì¢…ë£Œ ë°©ì‹ ì„ íƒ ---
mode = st.radio("ë°œí™” ì¢…ë£Œ ë°©ì‹", ("ë¬´ìŒ ìë™ ì¢…ë£Œ", "ê³ ì • ê¸¸ì´ ì œí•œ"), horizontal=True)

if mode == "ë¬´ìŒ ìë™ ì¢…ë£Œ":
    silence_sec = st.slider("ë¬´ìŒ ì§€ì† ì‹œê°„(ì´ˆ)", 1.0, 5.0, 2.0, 0.5)
    silence_thresh = st.slider("ë¬´ìŒ ì„ê³„(RMS, ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)", 0.002, 0.03, 0.01, 0.002)
    safety_cap = st.slider("ì•ˆì „ ìµœëŒ€ ê¸¸ì´(ì´ˆ)", 5, 30, 15)
    st.caption(f"ğŸ’¡ ì—°ì† ë¬´ìŒì´ {silence_sec}ì´ˆ ì´ìƒì´ë©´ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤. (ì•ˆì „ ìµœëŒ€ {safety_cap}ì´ˆ)")
else:
    duration = st.slider("ë°œí™” ê¸¸ì´ ì œí•œ (ì´ˆ)", 3, 15, 5)
    st.caption(f"ğŸ’¡ ì´ ë°œí™” ì‹œê°„ {duration}ì´ˆê°€ ì§€ë‚˜ë©´ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤.")

st.divider()

# --- íŠ¸ë¦¬ê±° ë²„íŠ¼ ---
if st.button("My turn"):
    # 1) ë…¹ìŒ
    if mode == "ë¬´ìŒ ìë™ ì¢…ë£Œ":
        audio, fs = record_audio_vad(
            silence_sec=silence_sec, fs=16000,
            silence_thresh=silence_thresh, max_total_sec=safety_cap
        )
    else:
        audio, fs = record_audio_fixed(duration=duration, fs=16000)

    # 2) STT
    with st.spinner("ğŸ“ ì¸ì‹ ì¤‘..."):
        user_text = run_stt(audio, fs)

    if user_text:
        st.markdown(f"**You:** {user_text}")

        # 3) LLM
        with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
            ai_reply = generate_ai_response(user_text, system_prompt=SYSTEM_PROMPT)
            st.session_state.conversation.append({"user": user_text, "ai": ai_reply})

        st.markdown(f"**AI Tutor:** {ai_reply}")

        # 4) TTS (ì• ë‹ˆë©”ì´ì…˜ ì—†ìŒ)
        with st.spinner("ğŸ—£ï¸ ë°œí™” ì¬ìƒ ì¤‘..."):
            speak(ai_reply)
    else:
        st.warning("Could not recognize any speech. Please try again.")

# --- ëŒ€í™” ë¡œê·¸(í™”ë©´ í‘œì‹œ) ---
st.markdown("## ğŸ’¬ ëŒ€í™” ë‚´ìš©")
for turn in st.session_state.conversation:
    if turn.get("user"):
        st.markdown(f"**You:** {turn['user']}")
    if turn.get("ai"):
        st.markdown(f"**AI Tutor:** {turn['ai']}")

# ===============================
# ğŸ“„ ì „ì²´ ëŒ€í™” ë³´ê¸° / ë‹¤ìš´ë¡œë“œ(.md/.json/.csv)
# ===============================
def get_full_transcript_md():
    lines = []
    for turn in st.session_state.conversation:
        if turn.get("user"): lines.append(f"**You:** {turn['user']}")
        if turn.get("ai"):   lines.append(f"**AI Tutor:** {turn['ai']}")
        lines.append("---")
    return "\n\n".join(lines[:-1]) if lines else "_(no conversation yet)_"

def get_full_transcript_json():
    return json.dumps(st.session_state.conversation, ensure_ascii=False, indent=2)

def get_full_transcript_csv():
    buf = StringIO()
    writer = csv.DictWriter(buf, fieldnames=["user", "ai"])
    writer.writeheader()
    for turn in st.session_state.conversation:
        writer.writerow({"user": turn.get("user",""), "ai": turn.get("ai","")})
    return buf.getvalue()

st.markdown("## ğŸ“„ ì „ì²´ ëŒ€í™” ë³´ê¸° / ì €ì¥")
with st.expander("ì „ì²´ ëŒ€í™” í¼ì¹˜ê¸°"):
    st.markdown(get_full_transcript_md())

c1, c2, c3 = st.columns(3)
with c1:
    st.download_button("â¬‡ï¸ Save .md", data=get_full_transcript_md(),
                       file_name="conversation.md", mime="text/markdown")
with c2:
    st.download_button("â¬‡ï¸ Save .json", data=get_full_transcript_json(),
                       file_name="conversation.json", mime="application/json")
with c3:
    st.download_button("â¬‡ï¸ Save .csv", data=get_full_transcript_csv(),
                       file_name="conversation.csv", mime="text/csv")
