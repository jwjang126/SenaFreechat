# ğŸ”Š SENA - ì•ˆì •í™” ë²„íŠ¼ ê¸°ë°˜ ë…¹ìŒ + ëŒ€í™” ë¡œê·¸
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from TTS.api import TTS
import sounddevice as sd
import numpy as np
import tempfile
import soundfile as sf
import time
from io import StringIO
import datetime

# -------------------------------
# ëª¨ë¸ & TTS ë¡œë“œ
# -------------------------------
MODEL_NAME = "meta-llama/Llama-3.2-1B"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

@st.cache_resource(show_spinner=True)
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)
    return tokenizer, model

tokenizer, model = load_model()

@st.cache_resource
def load_tts():
    tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC",
              progress_bar=False,
              gpu=torch.cuda.is_available())
    return tts

tts = load_tts()

# -------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -------------------------------
if "conversation" not in st.session_state:
    st.session_state.conversation = []

# -------------------------------
# ë…¹ìŒ í•¨ìˆ˜
# -------------------------------
def record_audio_fixed(duration=5, fs=16000):
    """duration ì´ˆ ë™ì•ˆ ë…¹ìŒí•˜ê³  ë°˜í™˜ (ê³ ì • ê¸¸ì´)"""
    st.info(f"ğŸ”´ Listening for {duration} seconds...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
    sd.wait()
    st.success("âœ… Finished!")
    return (audio.flatten().astype(np.float32)/32768.0), fs

def record_audio_vad(silence_sec=2.0, fs=16000, silence_thresh=0.01, max_total_sec=15):
    """ë¬´ìŒì´ silence_sec ì´ìƒ ì§€ì†ë˜ë©´ ìë™ ì¢…ë£Œ. ì•ˆì „ìƒ max_total_sec ë„˜ì–´ê°€ë©´ ê°•ì œ ì¢…ë£Œ."""
    st.info(f"ğŸ”´ Listening... ë¬´ìŒ {silence_sec}ì´ˆ ì§€ì† ì‹œ ìë™ ì¢…ë£Œ (ìµœëŒ€ {max_total_sec}ì´ˆ)")
    frames = []
    block_dur = 0.05
    block_size = int(fs*block_dur)
    silent_run = 0.0
    start = time.time()

    with sd.InputStream(samplerate=fs, channels=1, dtype="float32") as stream:
        while True:
            block, _ = stream.read(block_size)
            x = block[:, 0]
            frames.append(x.copy())
            rms = float(np.sqrt(np.mean(x**2) + 1e-12))
            silent_run = (silent_run + block_dur) if rms < silence_thresh else 0.0
            if silent_run >= silence_sec:
                break
            if time.time() - start >= max_total_sec:
                break

    audio = np.concatenate(frames).astype(np.float32) if frames else np.zeros(0, dtype=np.float32)
    st.success("âœ… Finished!")
    return audio, fs

# -------------------------------
# STT
# -------------------------------
def run_stt(audio, fs):
    tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
    sf.write(tmp.name, audio, fs)
    import whisper
    model = whisper.load_model("base", device="cpu")
    result = model.transcribe(tmp.name, task="transcribe", language="en", temperature=0)
    return result.get("text", "").strip()

# -------------------------------
# ì´ì „ ëŒ€í™” ìš”ì•½
# -------------------------------
if "conversation" not in st.session_state:
    st.session_state.conversation = []
if "conversation_summary" not in st.session_state:
    st.session_state.conversation_summary = ""

MAX_CONTEXT = 10

# -------------------------------
# LLM ë‹µë³€ ìƒì„±
# -------------------------------
def generate_ai_response(user_input):
    recent_convos = st.session_state.conversation[-MAX_CONTEXT:]

    context_text = ""
    if st.session_state.conversation_summary:
        context_text += f"[Summary of previous conversation]\n{st.session_state.conversation_summary}\n\n"

    for turn in recent_convos:
        context_text += f"Student: {turn['user']}\nTutor: {turn.get('ai','')}\n"

    prompt = f"""
You are a friendly English conversation tutor.
Your Persona:
- You are friendly, encouraging, and patient.
- Your goal is to make the student feel comfortable and encourage them to speak more.

Conversation Rules:
1.  **Be expressive:** Your response should be around 3-4 complete sentences.
2.  **Always ask a question:** You MUST end your response with a question to keep the conversation going.
3.  **Paraphrase, Don't Repeat:** You MUST NEVER repeat the student's sentences or key phrases.
4.  **Stay in Your Role:** You are the 'Tutor'. You MUST NOT write the "Student:" part of the conversation.
5.  Respond naturally according to the student's level.
6.  End sentences properly: All sentences must end with proper punctuation (., !, ?).

The student has provided the following topic: "{user_input}".

Level guidance:
- Difficulty: {level}
- Student description:
    - ì´ˆê¸‰: Think the student is a high school student. Use simple words and short sentences.
    - ì¤‘ê¸‰: Think the student is an adult learner. Use moderate vocabulary and clear explanations.
    - ê³ ê¸‰: Think the student wants to speak like a native speaker. Use advanced vocabulary and natural expressions.
- Expected response length: around {sentence_count} sentences.


---
**Examples of what to do and what NOT to do:**

**(O) Good Example - Asks a question:**
Me: "I enjoyed watching a movie yesterday."
You: "That sounds like a fun way to relax! It's great to take a break sometimes. What kind of film was it?"

**(X) Bad Example - Does NOT ask a question:**
Me: "I like listening to music."
You: "That's a great hobby. Music can be very relaxing."
**(This is bad because it doesn't ask a question and ends the conversation.)**

**(O) Good Example - Ends properly and asks a question:**
Me: "I enjoyed watching a movie yesterday."
You: "That sounds like a fun way to relax! It's great to take a break sometimes. What kind of film was it?"

**(X) Bad Example - Does not end properly:**
Me: "I like listening to music."
You: "That's a great hobby. Music can be very relaxing"

Send only the answer of "You" in print.
---

Context so far:
{context_text}

Tutor:"""
    
    inputs = tokenizer(prompt, return_tensors="pt").to(DEVICE)
    outputs = model.generate(
        **inputs,
        max_new_tokens=80,
        temperature=0.7,
        pad_token_id=tokenizer.eos_token_id,
        do_sample=True,
    )
    reply = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Tutor: ë’¤ì— ì˜¤ëŠ” ë¶€ë¶„ë§Œ ì¶”ì¶œ
    if "Tutor:" in reply:
        reply = reply.split("Tutor:")[-1].strip()

    if (len(st.session_state.conversation) + 1) % MAX_CONTEXT == 0:
        summary_prompt = f"Summarize the following conversation briefly:\n{context_text}"
        summary_inputs = tokenizer(summary_prompt, return_tensors="pt").to(DEVICE)
        summary_outputs = model.generate(**summary_inputs, max_new_tokens=100)
        st.session_state.conversation_summary = tokenizer.decode(summary_outputs[0], skip_special_tokens=True)

    return reply


# -------------------------------
# TTS ì¬ìƒ
# -------------------------------
def speak(text):
    wav = tts.tts(text=text)
    sd.play(wav, samplerate=tts.synthesizer.output_sample_rate)
    sd.wait()

# -------------------------------
# Streamlit UI
# -------------------------------
st.title("ğŸ”Š SENA - English Tutor")
st.write("ğŸ¤ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”í•˜ì„¸ìš”!")
topic = st.text_input("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
level = st.selectbox("ìˆ˜ì¤€ì„ ì„ íƒí•˜ì„¸ìš”", ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"])

# ìˆ˜ì¤€ë³„ ë¬¸ì¥ ìˆ˜ ì„¤ì •
sentence_count = {"ì´ˆê¸‰": 2, "ì¤‘ê¸‰": 4, "ê³ ê¸‰": 6}[level]

# -------------------------------
# ë…¹ìŒ ì¢…ë£Œ ë°©ì‹ ì„ íƒ
# -------------------------------
st.sidebar.header("ğŸšï¸ ë…¹ìŒ ì„¤ì •")
mode = st.sidebar.radio("ë°œí™” ì¢…ë£Œ ë°©ì‹", ("ë¬´ìŒ ìë™ ì¢…ë£Œ", "ê³ ì • ê¸¸ì´ ì œí•œ"), horizontal=True)

if mode == "ë¬´ìŒ ìë™ ì¢…ë£Œ":
    silence_sec = st.sidebar.slider("ë¬´ìŒ ì§€ì† ì‹œê°„(ì´ˆ)", 1.0, 5.0, 2.0, 0.5, format="%.1f")
    with st.expander("ê³ ê¸‰ ì„¤ì • ë³´ê¸°"):
        silence_thresh = st.sidebar.slider("ë¬´ìŒ ì„ê³„(RMS x100, ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)", 0.2, 3.0, 1.0, 0.4, format="%.1f")/100
        safety_cap = st.sidebar.slider("ìµœëŒ€ ë°œí™” ì‹œê°„(ì´ˆ)", 5, 30, 15)
    st.sidebar.caption(f"ğŸ’¡ ì—°ì† ë¬´ìŒì´ {silence_sec}ì´ˆ ì´ìƒì´ë©´ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤. (ìµœëŒ€ ë°œí™” ì‹œê°„ {safety_cap}ì´ˆ)")
else:
    duration = st.sidebar.slider("ë°œí™” ê¸¸ì´ ì œí•œ (ì´ˆ)", 3, 15, 5)
    st.sidebar.caption(f"ğŸ’¡ ì´ ë°œí™” ì‹œê°„ {duration}ì´ˆê°€ ì§€ë‚˜ë©´ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤.")

st.divider()

# -------------------------------
# ë…¹ìŒ + STT + LLM + TTS íŠ¸ë¦¬ê±°
# -------------------------------
if st.button("My turn"):
    if mode == "ë¬´ìŒ ìë™ ì¢…ë£Œ":
        audio, fs = record_audio_vad(
            silence_sec=silence_sec,
            fs=16000,
            silence_thresh=silence_thresh,
            max_total_sec=safety_cap
        )
    else:
        audio, fs = record_audio_fixed(duration, fs=16000)

    with st.spinner("ğŸ“ ì¸ì‹ ì¤‘..."):
        user_text = run_stt(audio, fs)
    
    if user_text:
        st.markdown(f"**You:** {user_text}")
        with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
            ai_reply = generate_ai_response(user_text)
            st.session_state.conversation.append({"user": user_text, "ai": ai_reply})
        with st.spinner("ğŸ—£ï¸ ë°œí™” ì¬ìƒ ì¤‘..."):
            speak(ai_reply)
    else:
        st.warning("Could not recognize any speech. Please try again.")


# -------------------------------
# ğŸ“„ ì „ì²´ ëŒ€í™” ë³´ê¸° / ë‹¤ìš´ë¡œë“œ(.txt)
# -------------------------------
def get_full_transcript_txt():
    """í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì „ì²´ ëŒ€í™” ë°˜í™˜"""
    lines = []
    for turn in st.session_state.conversation:
        if turn.get("user"): lines.append(f"You: {turn['user']}")
        if turn.get("ai"):   lines.append(f"AI Tutor: {turn['ai']}")
        lines.append("-"*40)
    return "\n".join(lines[:-1]) if lines else "(no conversation yet)"

# -------------------------------
# Streamlit UI
# -------------------------------
#st.markdown("##### ğŸ“„ ì „ì²´ ëŒ€í™” ë³´ê¸° / ë‹¤ìš´ë¡œë“œ")

today_str = datetime.datetime.now().strftime("%y%m%d")
safe_topic = topic.replace(" ", "_") if topic else "NoTopic"
file_name = f"{today_str}_{safe_topic}_{level}.txt"

with st.expander("ğŸ“„ ì „ì²´ ëŒ€í™” ë³´ê¸° / ë‹¤ìš´ë¡œë“œ"):
    st.text_area("ì „ì²´ ëŒ€í™” ë‚´ìš©", value=get_full_transcript_txt(), height=300)
    st.download_button("â¬‡ï¸ Save .txt", data=get_full_transcript_txt(),
                       file_name=file_name, mime="text/plain")