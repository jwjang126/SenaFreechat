{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae6b00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# stt_llama_chat_safe.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import webrtcvad\n",
    "import whisper\n",
    "import tempfile\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "# ------------------------------\n",
    "# 1️⃣ VAD 기반 녹음 함수\n",
    "# ------------------------------\n",
    "def record_with_vad(max_seconds=90, fs=16000, frame_ms=20, vad_mode=1, silence_sec=3):\n",
    "    vad = webrtcvad.Vad()\n",
    "    vad.set_mode(vad_mode)\n",
    "\n",
    "    frame_len = int(fs * frame_ms / 1000)\n",
    "    silence_win = int(silence_sec * 1000 / frame_ms)\n",
    "    recent = deque(maxlen=max(silence_win, 1))\n",
    "\n",
    "    print(\"🎤 녹음 시작 (말씀하세요). 무음이 되면 자동 종료됩니다...\")\n",
    "\n",
    "    recorded = []\n",
    "    started = time.time()\n",
    "    speech_started = False\n",
    "\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        recorded.append(indata.copy())\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=fs, channels=1, dtype='int16', callback=callback):\n",
    "            while True:\n",
    "                time.sleep(frame_ms / 1000.0)\n",
    "                if not recorded:\n",
    "                    continue\n",
    "\n",
    "                frame = recorded[-1].flatten()\n",
    "                if len(frame) >= frame_len:\n",
    "                    speech = vad.is_speech(frame[:frame_len].tobytes(), sample_rate=fs)\n",
    "                    recent.append(1 if speech else 0)\n",
    "                    if speech:\n",
    "                        speech_started = True\n",
    "\n",
    "                if speech_started and len(recent) == recent.maxlen and sum(recent) == 0:\n",
    "                    print(\"🛑 무음 지속 → 종료\")\n",
    "                    break\n",
    "\n",
    "                if time.time() - started > max_seconds:\n",
    "                    print(\"⏱ 최대 녹음 시간 도달, 종료합니다.\")\n",
    "                    break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n사용자 중단\")\n",
    "\n",
    "    if not recorded:\n",
    "        return None, fs\n",
    "\n",
    "    audio = np.concatenate(recorded, axis=0).astype(np.int16)\n",
    "    return audio, fs\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2️⃣ Whisper STT 함수\n",
    "# ------------------------------\n",
    "def run_stt(audio, fs, model_name=\"base\", task=\"transcribe\", device=\"cpu\"):\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    tmp_path = tmp.name\n",
    "    tmp.close()\n",
    "    sf.write(tmp_path, audio, fs)\n",
    "    print(f\"💾 임시 파일 저장: {tmp_path}\")\n",
    "\n",
    "    print(\"🌀 Whisper 모델 로드 중...\")\n",
    "    model = whisper.load_model(model_name, device=device)\n",
    "\n",
    "    print(f\"📖 변환 중... (task={task})\")\n",
    "    result = model.transcribe(tmp_path, task=task)\n",
    "    text = result.get(\"text\", \"\").strip()\n",
    "\n",
    "    try:\n",
    "        os.remove(tmp_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3️⃣ LLaMA 대화 + 스트리밍\n",
    "# ------------------------------\n",
    "def run_llama_conversation(hf_token, difficulty, duration=600, device=\"cpu\"):\n",
    "    print(\"🤖 LLaMA 모델 로드 중...\")\n",
    "    model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token).to(device)\n",
    "\n",
    "    history = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        elapsed = time.time() - start_time\n",
    "        is_final = elapsed > duration  # 종료 직전 플래그\n",
    "\n",
    "        # 🎤 사용자 발화\n",
    "        audio, fs = record_with_vad(max_seconds=20, fs=16000, vad_mode=3, silence_sec=2)\n",
    "        if audio is None:\n",
    "            print(\"❌ 녹음 실패, 대화 종료\")\n",
    "            break\n",
    "\n",
    "        stt_text = run_stt(audio, fs, model_name=\"base\", task=\"transcribe\", device=\"cpu\")\n",
    "        if not stt_text:\n",
    "            print(\"❌ 음성 인식 결과 없음\")\n",
    "            continue\n",
    "\n",
    "        history.append((\"사용자\", stt_text))\n",
    "\n",
    "        # 📖 프롬프트 구성\n",
    "        dialogue = \"\\n\".join([f\"{role}: {msg}\" for role, msg in history])\n",
    "\n",
    "        if is_final:\n",
    "            prompt = f\"\"\"\n",
    "너는 {difficulty} 답변을 해주는 조교야.\n",
    "지금까지 사용자의 대화를 정리하고 마지막으로 따뜻하게 마무리 인사를 해줘.\n",
    "예: '오늘 대화 수고했어! 다음에 또 이야기하자.'\n",
    "\n",
    "{dialogue}\n",
    "AI:\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "너는 {difficulty} 답변을 해주는 조교야.\n",
    "아래는 사용자와 AI의 대화다. 반드시 {difficulty} 답변을 해라.\n",
    "\n",
    "{dialogue}\n",
    "AI:\"\"\"\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        print(\"\\n===== 🤖 AI 답변 (Streaming) =====\")\n",
    "        streamer = TextStreamer(tokenizer)\n",
    "        output = model.generate(**inputs, max_new_tokens=256, streamer=streamer)\n",
    "\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        ai_answer = response.split(\"AI:\")[-1].strip()\n",
    "        history.append((\"AI\", ai_answer))\n",
    "        print(\"\\n===============================\\n\")\n",
    "\n",
    "        if is_final:\n",
    "            print(\"⏰ 대화 10분 종료, 프로그램을 마무리합니다.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4️⃣ 메인\n",
    "# ------------------------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"STT + LLaMA Chatbot (대화 히스토리 + 난이도 유지)\")\n",
    "    parser.add_argument(\"--difficulty\", default=\"쉽게\", help=\"답변 난이도 (예: 쉽게, 어렵게, 자세히)\")\n",
    "    parser.add_argument(\"--duration\", type=int, default=600, help=\"대화 지속 시간(초, 기본 600초=10분)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")  # ✅ 환경 변수에서 안전하게 가져오기\n",
    "    if not hf_token:\n",
    "        print(\"❌ 환경 변수 HF_TOKEN에 Hugging Face 토큰을 설정하세요.\")\n",
    "        return\n",
    "\n",
    "    run_llama_conversation(hf_token, args.difficulty, duration=args.duration, device=\"cpu\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
