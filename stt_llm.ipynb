{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae6b00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# stt_llama_chat_safe.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import webrtcvad\n",
    "import whisper\n",
    "import tempfile\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "# ------------------------------\n",
    "# 1ï¸âƒ£ VAD ê¸°ë°˜ ë…¹ìŒ í•¨ìˆ˜\n",
    "# ------------------------------\n",
    "def record_with_vad(max_seconds=90, fs=16000, frame_ms=20, vad_mode=1, silence_sec=3):\n",
    "    vad = webrtcvad.Vad()\n",
    "    vad.set_mode(vad_mode)\n",
    "\n",
    "    frame_len = int(fs * frame_ms / 1000)\n",
    "    silence_win = int(silence_sec * 1000 / frame_ms)\n",
    "    recent = deque(maxlen=max(silence_win, 1))\n",
    "\n",
    "    print(\"ğŸ¤ ë…¹ìŒ ì‹œì‘ (ë§ì”€í•˜ì„¸ìš”). ë¬´ìŒì´ ë˜ë©´ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤...\")\n",
    "\n",
    "    recorded = []\n",
    "    started = time.time()\n",
    "    speech_started = False\n",
    "\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        recorded.append(indata.copy())\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=fs, channels=1, dtype='int16', callback=callback):\n",
    "            while True:\n",
    "                time.sleep(frame_ms / 1000.0)\n",
    "                if not recorded:\n",
    "                    continue\n",
    "\n",
    "                frame = recorded[-1].flatten()\n",
    "                if len(frame) >= frame_len:\n",
    "                    speech = vad.is_speech(frame[:frame_len].tobytes(), sample_rate=fs)\n",
    "                    recent.append(1 if speech else 0)\n",
    "                    if speech:\n",
    "                        speech_started = True\n",
    "\n",
    "                if speech_started and len(recent) == recent.maxlen and sum(recent) == 0:\n",
    "                    print(\"ğŸ›‘ ë¬´ìŒ ì§€ì† â†’ ì¢…ë£Œ\")\n",
    "                    break\n",
    "\n",
    "                if time.time() - started > max_seconds:\n",
    "                    print(\"â± ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ë„ë‹¬, ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                    break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nì‚¬ìš©ì ì¤‘ë‹¨\")\n",
    "\n",
    "    if not recorded:\n",
    "        return None, fs\n",
    "\n",
    "    audio = np.concatenate(recorded, axis=0).astype(np.int16)\n",
    "    return audio, fs\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2ï¸âƒ£ Whisper STT í•¨ìˆ˜\n",
    "# ------------------------------\n",
    "def run_stt(audio, fs, model_name=\"base\", task=\"transcribe\", device=\"cpu\"):\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    tmp_path = tmp.name\n",
    "    tmp.close()\n",
    "    sf.write(tmp_path, audio, fs)\n",
    "    print(f\"ğŸ’¾ ì„ì‹œ íŒŒì¼ ì €ì¥: {tmp_path}\")\n",
    "\n",
    "    print(\"ğŸŒ€ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "    model = whisper.load_model(model_name, device=device)\n",
    "\n",
    "    print(f\"ğŸ“– ë³€í™˜ ì¤‘... (task={task})\")\n",
    "    result = model.transcribe(tmp_path, task=task)\n",
    "    text = result.get(\"text\", \"\").strip()\n",
    "\n",
    "    try:\n",
    "        os.remove(tmp_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3ï¸âƒ£ LLaMA ëŒ€í™” + ìŠ¤íŠ¸ë¦¬ë°\n",
    "# ------------------------------\n",
    "def run_llama_conversation(hf_token, difficulty, duration=600, device=\"cpu\"):\n",
    "    print(\"ğŸ¤– LLaMA ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "    model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token).to(device)\n",
    "\n",
    "    history = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        elapsed = time.time() - start_time\n",
    "        is_final = elapsed > duration  # ì¢…ë£Œ ì§ì „ í”Œë˜ê·¸\n",
    "\n",
    "        # ğŸ¤ ì‚¬ìš©ì ë°œí™”\n",
    "        audio, fs = record_with_vad(max_seconds=20, fs=16000, vad_mode=3, silence_sec=2)\n",
    "        if audio is None:\n",
    "            print(\"âŒ ë…¹ìŒ ì‹¤íŒ¨, ëŒ€í™” ì¢…ë£Œ\")\n",
    "            break\n",
    "\n",
    "        stt_text = run_stt(audio, fs, model_name=\"base\", task=\"transcribe\", device=\"cpu\")\n",
    "        if not stt_text:\n",
    "            print(\"âŒ ìŒì„± ì¸ì‹ ê²°ê³¼ ì—†ìŒ\")\n",
    "            continue\n",
    "\n",
    "        history.append((\"ì‚¬ìš©ì\", stt_text))\n",
    "\n",
    "        # ğŸ“– í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "        dialogue = \"\\n\".join([f\"{role}: {msg}\" for role, msg in history])\n",
    "\n",
    "        if is_final:\n",
    "            prompt = f\"\"\"\n",
    "ë„ˆëŠ” {difficulty} ë‹µë³€ì„ í•´ì£¼ëŠ” ì¡°êµì•¼.\n",
    "ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©ìì˜ ëŒ€í™”ë¥¼ ì •ë¦¬í•˜ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ë”°ëœ»í•˜ê²Œ ë§ˆë¬´ë¦¬ ì¸ì‚¬ë¥¼ í•´ì¤˜.\n",
    "ì˜ˆ: 'ì˜¤ëŠ˜ ëŒ€í™” ìˆ˜ê³ í–ˆì–´! ë‹¤ìŒì— ë˜ ì´ì•¼ê¸°í•˜ì.'\n",
    "\n",
    "{dialogue}\n",
    "AI:\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "ë„ˆëŠ” {difficulty} ë‹µë³€ì„ í•´ì£¼ëŠ” ì¡°êµì•¼.\n",
    "ì•„ë˜ëŠ” ì‚¬ìš©ìì™€ AIì˜ ëŒ€í™”ë‹¤. ë°˜ë“œì‹œ {difficulty} ë‹µë³€ì„ í•´ë¼.\n",
    "\n",
    "{dialogue}\n",
    "AI:\"\"\"\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        print(\"\\n===== ğŸ¤– AI ë‹µë³€ (Streaming) =====\")\n",
    "        streamer = TextStreamer(tokenizer)\n",
    "        output = model.generate(**inputs, max_new_tokens=256, streamer=streamer)\n",
    "\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        ai_answer = response.split(\"AI:\")[-1].strip()\n",
    "        history.append((\"AI\", ai_answer))\n",
    "        print(\"\\n===============================\\n\")\n",
    "\n",
    "        if is_final:\n",
    "            print(\"â° ëŒ€í™” 10ë¶„ ì¢…ë£Œ, í”„ë¡œê·¸ë¨ì„ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4ï¸âƒ£ ë©”ì¸\n",
    "# ------------------------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"STT + LLaMA Chatbot (ëŒ€í™” íˆìŠ¤í† ë¦¬ + ë‚œì´ë„ ìœ ì§€)\")\n",
    "    parser.add_argument(\"--difficulty\", default=\"ì‰½ê²Œ\", help=\"ë‹µë³€ ë‚œì´ë„ (ì˜ˆ: ì‰½ê²Œ, ì–´ë µê²Œ, ìì„¸íˆ)\")\n",
    "    parser.add_argument(\"--duration\", type=int, default=600, help=\"ëŒ€í™” ì§€ì† ì‹œê°„(ì´ˆ, ê¸°ë³¸ 600ì´ˆ=10ë¶„)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")  # âœ… í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°\n",
    "    if not hf_token:\n",
    "        print(\"âŒ í™˜ê²½ ë³€ìˆ˜ HF_TOKENì— Hugging Face í† í°ì„ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    run_llama_conversation(hf_token, args.difficulty, duration=args.duration, device=\"cpu\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
