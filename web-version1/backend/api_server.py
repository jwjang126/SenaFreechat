import sys
import os
import json
import subprocess
import whisper
from TTS.api import TTS
import logging
import torch
from transformers import pipeline
import uvicorn
import base64
import uuid # ì„ì‹œ íŒŒì¼ ì´ë¦„ ìƒì„±ì„ ìœ„í•´ ì¶”ê°€

# FastAPI ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import JSONResponse

# --- ì´ ë¶€ë¶„ì€ process_audio.pyì™€ ë™ì¼í•©ë‹ˆë‹¤ ---
# --- ì„œë²„ ì‹œì‘ ì‹œ ë‹¨ í•œë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤! ---
logging.basicConfig(level=logging.INFO, stream=sys.stderr, format='%(levelname)s:%(name)s:%(message)s')

pipe = None
whisper_model = None
tts_model = None
try:
    print("Loading AI models... This might take a moment.", file=sys.stderr)
    pipe = pipeline("text-generation", model="meta-llama/Llama-3.2-1B", dtype=torch.bfloat16, device_map="auto")
    pipe.tokenizer.chat_template = (
        "{% for message in messages %}"
        "{{'<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n' + message['content'] + '<|eot_id|>'}}"
        "{% endfor %}"
        "{{'<|start_header_id|>assistant<|end_header_id|>\n\n'}}"
    )
    whisper_model = whisper.load_model("base")
    tts_model = TTS("tts_models/en/ljspeech/tacotron2-DDC")
    print("All models loaded successfully.", file=sys.stderr)
except Exception as e:
    print(f"Failed to load models: {e}", file=sys.stderr)
# -----------------------------------------------------------

# FastAPI ì•± ìƒì„±
app = FastAPI()

# '/process-audio' ê²½ë¡œë¡œ POST ìš”ì²­ì„ ì²˜ë¦¬í•  API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
@app.post("/process-audio/")
async def process_audio(
    audio: UploadFile = File(...),
    conversationHistory: str = Form(...),
    topic: str = Form(...),
    level: str = Form(...)
):
    # ì„ì‹œ íŒŒì¼ ê²½ë¡œë“¤ ìƒì„±
    temp_dir = "uploads"
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
    
    unique_filename = str(uuid.uuid4())
    input_webm_path = os.path.join(temp_dir, f"{unique_filename}.webm")
    input_wav_path = os.path.join(temp_dir, f"{unique_filename}_16k.wav")
    output_mp3_path = os.path.join(temp_dir, f"{unique_filename}.mp3")

    try:
        # 1. ì—…ë¡œë“œëœ webm íŒŒì¼ì„ ë””ìŠ¤í¬ì— ì €ì¥
        with open(input_webm_path, "wb") as buffer:
            buffer.write(await audio.read())

        # 2. webm -> wav ë³€í™˜ (ffmpeg ì‚¬ìš©)
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_webm_path, "-ac", "1", "-ar", "16000", "-f", "wav", input_wav_path],
            check=True, capture_output=True, text=True
        )

        # ------------------------------------------------
        # ì•„ë˜ëŠ” ê¸°ì¡´ process_audio.pyì˜ main í•¨ìˆ˜ ë¡œì§ê³¼ ê±°ì˜ ë™ì¼
        conversation_history = json.loads(conversationHistory) if conversationHistory else []

        # STT (Whisper)
        result = whisper_model.transcribe(input_wav_path)
        user_text = result.get("text", "").strip()

        # LLM í˜¸ì¶œ
        system_prompt_content = f"""You are 'Tutor', a friendly English conversation partner.
Today's conversation topic is: {topic}.
Please adjust your language difficulty to a {level} level for the student.
... (ì´í•˜ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì€ ë™ì¼)
"""
        system_prompt = {"role": "system", "content": system_prompt_content}
        messages = [system_prompt] + conversation_history + [{"role": "user", "content": user_text}]
        prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        outputs = pipe(
            prompt, 
            max_new_tokens=256, 
            do_sample=True, 
            temperature=0.7, 
            top_k=50, 
            top_p=0.95,
            repetition_penalty=1.2  # ğŸ‘ˆ ì´ ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”! (1.0ë³´ë‹¤ í° ê°’)
        )
        ai_reply = outputs[0]["generated_text"][len(prompt):].strip()
        ai_reply = ai_reply.replace("rbrakkendcode", "").strip()

        # TTS ë° MP3 ë³€í™˜
        temp_tts_wav = os.path.join(temp_dir, f"temp_tts_{unique_filename}.wav")
        tts_model.tts_to_file(text=ai_reply, file_path=temp_tts_wav)
        subprocess.run(
            ["ffmpeg", "-y", "-i", temp_tts_wav, output_mp3_path],
            check=True, capture_output=True, text=True
        )
        os.remove(temp_tts_wav)
        # ------------------------------------------------

        # 3. ìƒì„±ëœ mp3 íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜
        with open(output_mp3_path, "rb") as f:
            mp3_bytes = f.read()
            audio_base64 = base64.b64encode(mp3_bytes).decode('utf-8')
        
        return JSONResponse(content={
            "user_text": user_text,
            "ai_reply": ai_reply,
            "audio_base64": audio_base64 # mp3 íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ë‹¬
        })

    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        return JSONResponse(status_code=500, content={"error": str(e)})
    finally:
        # 4. ëª¨ë“  ì„ì‹œ íŒŒì¼ ì‚­ì œ
        for f_path in [input_webm_path, input_wav_path, output_mp3_path]:
            if os.path.exists(f_path):
                try:
                    os.remove(f_path)
                except Exception as e:
                    print(f"Error removing file {f_path}: {e}", file=sys.stderr)

# ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ê²½ìš° uvicorn ì„œë²„ë¥¼ 8000ë²ˆ í¬íŠ¸ë¡œ ì‹¤í–‰
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)