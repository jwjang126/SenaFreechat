import { useState, useRef } from "react";

// ë¬´ìŒ ê°ì§€ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ í›… (ì»´í¬ë„ŒíŠ¸ ì™¸ë¶€ì— ì •ì˜)
function useVAD(onStop, silenceDurationMs = 2000) {
  const audioContextRef = useRef(null);
  const mediaStreamSourceRef = useRef(null);
  const scriptProcessorNodeRef = useRef(null);
  const silenceStartRef = useRef(Date.now());

  const start = (stream) => {
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    audioContextRef.current = audioContext;
    const mediaStreamSource = audioContext.createMediaStreamSource(stream);
    mediaStreamSourceRef.current = mediaStreamSource;
    const bufferSize = 4096;
    const scriptProcessorNode = audioContext.createScriptProcessor(bufferSize, 1, 1);
    scriptProcessorNodeRef.current = scriptProcessorNode;
    const SILENCE_THRESHOLD = 0.01;

    scriptProcessorNode.onaudioprocess = (event) => {
      const input = event.inputBuffer.getChannelData(0);
      let sum = 0.0;
      for (let i = 0; i < input.length; ++i) {
        sum += input[i] * input[i];
      }
      const rms = Math.sqrt(sum / input.length);

      if (rms > SILENCE_THRESHOLD) {
        silenceStartRef.current = Date.now();
      } else {
        if (Date.now() - silenceStartRef.current > silenceDurationMs) {
          onStop();
          stop();
        }
      }
    };
    mediaStreamSource.connect(scriptProcessorNode);
    scriptProcessorNode.connect(audioContext.destination);
    silenceStartRef.current = Date.now();
  };

  const stop = () => {
    if (mediaStreamSourceRef.current) mediaStreamSourceRef.current.disconnect();
    if (scriptProcessorNodeRef.current) scriptProcessorNodeRef.current.disconnect();
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
    }
  };

  return { start, stop };
}

// ë©”ì¸ Freechat ì»´í¬ë„ŒíŠ¸
function Freechat() {
  const [topic, setTopic] = useState("");
  const [level, setLevel] = useState("ì´ˆê¸‰");
  const [conversation, setConversation] = useState([]);
  const [recording, setRecording] = useState(false);
  const [audioURL, setAudioURL] = useState(null);
  const [silenceDuration, setSilenceDuration] = useState(2);
  const [isSidebarOpen, setIsSidebarOpen] = useState(true);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  const handleStopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      mediaRecorderRef.current.stop();
      setRecording(false);
    }
  };

  const vad = useVAD(handleStopRecording, silenceDuration * 1000);

  const startRecording = async () => {
    if (audioURL) {
      try {
        const filename = audioURL.split("/").pop();
        await fetch("http://localhost:5000/delete-audio", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ filename }),
        });
      } catch (err) {
        console.error("Failed to request audio deletion:", err);
      }
      setAudioURL(null);
    }

    setRecording(true);
    audioChunksRef.current = [];
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorderRef.current = new MediaRecorder(stream, { mimeType: "audio/webm;codecs=opus" });

      mediaRecorderRef.current.ondataavailable = (e) => {
        if (e.data.size > 0) audioChunksRef.current.push(e.data);
      };

      mediaRecorderRef.current.onstop = async () => {
        vad.stop();
        const blob = new Blob(audioChunksRef.current, { type: "audio/webm;codecs=opus" });
        if (blob.size === 0) {
          alert("ë…¹ìŒëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.");
          setRecording(false);
          return;
        }

        const formData = new FormData();
        formData.append("audio", blob, "record.webm");
        const historyForAI = conversation.flatMap(turn => [
        { role: 'user', content: turn.user },
        { role: 'assistant', content: turn.ai }
      ]);
      formData.append('conversationHistory', JSON.stringify(historyForAI));
      formData.append('level', level);
      formData.append('topic', topic); 

        try {
          const response = await fetch("http://localhost:5000/process-audio", { method: "POST", body: formData });
          if (!response.ok) throw new Error("server error " + response.status);
          const data = await response.json();
          setConversation((prev) => [...prev, { user: data.user_text, ai: data.ai_reply }]);
          if (data.audio_file) {
            const url = `http://localhost:5000/${data.audio_file}`;
            setAudioURL(url);
            const audio = new Audio(url);
            audio.play().catch(e => console.log("Autoplay was prevented.", e));
          }
        } catch (err) {
          console.error("ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨:", err);
        }
      };

      mediaRecorderRef.current.start();
      vad.start(stream);
    } catch (err) {
      console.error("ë…¹ìŒ ì‹¤íŒ¨:", err);
      setRecording(false);
    }
  };

  const manualStopRecording = () => {
    vad.stop();
    handleStopRecording();
  };

  return (
    <div style={{ display: "flex", fontFamily: "sans-serif" }}>
      <div style={{
        width: isSidebarOpen ? "250px" : "0px",
        padding: isSidebarOpen ? "1rem" : "0",
        borderRight: isSidebarOpen ? "1px solid #eee" : "none",
        background: "#f9f9f9",
        overflow: "hidden",
        transition: "width 0.3s ease, padding 0.3s ease"
      }}>
        <h3>ğŸšï¸ ë…¹ìŒ ì„¤ì •</h3>
        <hr/>
        <label htmlFor="silence-duration" style={{ fontSize: '0.9rem', color: '#333' }}>ë¬´ìŒ ì§€ì† ì‹œê°„ (ì´ˆ)</label>
        <p style={{ textAlign: "center", fontWeight: "bold", fontSize: '1.2rem', color: '#007bff', margin: '0.5rem 0' }}>{silenceDuration.toFixed(1)}ì´ˆ</p>
        <input
          type="range"
          id="silence-duration"
          min="1"
          max="5"
          step="0.5"
          value={silenceDuration}
          onChange={(e) => setSilenceDuration(parseFloat(e.target.value))}
          style={{ width: "100%" }}
        />
        <hr/>
        <p style={{ fontSize: '0.8rem', color: '#666' }}>
          ğŸ’¡ ë…¹ìŒ ì‹œì‘ í›„, ì„¤ì •ëœ ì‹œê°„ ë™ì•ˆ ë§ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë…¹ìŒì´ ì¢…ë£Œë©ë‹ˆë‹¤.
        </p>
      </div>

      <div style={{ flex: 1, padding: "1rem 2rem", position: 'relative' }}>
        <button 
          onClick={() => setIsSidebarOpen(!isSidebarOpen)}
          style={{
            position: 'absolute',
            left: isSidebarOpen ? '-15px' : '15px',
            top: '1rem',
            background: '#007bff',
            color: 'white',
            border: 'none',
            borderRadius: '50%',
            width: '30px',
            height: '30px',
            cursor: 'pointer',
            fontSize: '1rem',
            lineHeight: '30px',
            textAlign: 'center',
            transition: 'left 0.3s ease',
            zIndex: 10
          }}
        >
          {isSidebarOpen ? "â€¹" : "â€º"}
        </button>

        <h2>ğŸ¤ AI TUTOR</h2>
        
        <div style={{ marginBottom: "1.5rem" }}>
          <input
              type="text"
              placeholder="ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
              value={topic}
              onChange={(e) => setTopic(e.target.value)}
              style={{ marginRight: "1rem", padding: "8px", borderRadius: "4px", border: "1px solid #ccc" }}
          />
          <select value={level} onChange={(e) => setLevel(e.target.value)} style={{ padding: "8px", borderRadius: "4px", border: "1px solid #ccc" }}>
              <option>ì´ˆê¸‰</option>
              <option>ì¤‘ê¸‰</option>
              <option>ê³ ê¸‰</option>
          </select>
        </div>

        <div style={{ marginBottom: "1.5rem" }}>
          {!recording ? (
              <button onClick={startRecording} style={{ padding: '10px 20px', fontSize: '1rem', cursor: 'pointer' }}>ë…¹ìŒ ì‹œì‘</button>
          ) : (
              <button onClick={manualStopRecording} style={{ padding: '10px 20px', fontSize: '1rem', cursor: 'pointer', background: '#dc3545', color: 'white' }}>ë…¹ìŒ ìˆ˜ë™ ì¢…ë£Œ</button>
          )}
        </div>
        
        {audioURL && (
            <div style={{ marginBottom: "1.5rem" }}>
                <p>AI ìŒì„± ì¬ìƒ:</p>
                <audio src={audioURL} controls />
            </div>
        )}

        <div style={{ border: "1px solid #eee", background: "#fff", borderRadius: "8px", padding: "10px", height: "300px", overflowY: "scroll" }}>
            {conversation.length === 0 ? (
                <p style={{ color: '#888' }}>(ëŒ€í™” ê¸°ë¡ ì—†ìŒ)</p>
            ) : (
                conversation.map((turn, index) => (
                    <div key={index} style={{ marginBottom: '1rem' }}>
                        <p style={{ margin: '0 0 5px 0' }}><b>You:</b> {turn.user}</p>
                        <p style={{ margin: 0, color: '#007bff' }}><b>AI Tutor:</b> {turn.ai}</p>
                        {index < conversation.length - 1 && <hr style={{ border: 0, borderTop: '1px solid #eee', margin: '1rem 0' }} />}
                    </div>
                ))
            )}
        </div>
      </div>
    </div>
  );
}

export default Freechat;

